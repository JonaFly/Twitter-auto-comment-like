{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from collections import defaultdict\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from lstm_network import LSTM_network\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from heatmap import html_heatmap\n",
    "\n",
    "# load the keras model and the word-2-vec dictionary. The keras model is trained for the sentiment analysis dataset\n",
    "# from stanford university and classifies movie reviews into five different categories.\n",
    "if True:\n",
    "    # this is the model which train on sigmoid and binary_crossentropy\n",
    "    keras_model = load_model('model/mymodel.hdf5')\n",
    "    n_classes = 1\n",
    "else:\n",
    "    # this is the model which train on softmax and sparse_categorical_crossentropy\n",
    "    keras_model = load_model('tmp/trainmodel.model')\n",
    "    n_classes = 2\n",
    "f = open(\"model/myvec.vector\", mode=\"r\", encoding=\"utf-8\")\n",
    "w2v = defaultdict()\n",
    "line = f.readline()\n",
    "while line != \"\":\n",
    "    line = line.strip().split()\n",
    "    w2v[line[0]] = [float(i) for i in line[1:]]\n",
    "    assert len(w2v[line[0]]) == 60\n",
    "    line = f.readline()\n",
    "f.close()\n",
    "\n",
    "# create the lstm-lrp model\n",
    "n_hidden = 60\n",
    "embedding_dim = 60\n",
    "\n",
    "# the max len of sentence\n",
    "n_words_len = 40\n",
    "weights = keras_model.get_weights()\n",
    "# if the len is seven, maybe you need to  execute \"weights.append(np.zeros((n_classes,)))\"\n",
    "print(len(weights))\n",
    "\n",
    "# our keras model has no bias in the final dense layer. Therefore we add a bias of zero to the weights\n",
    "# weights.append(np.zeros((n_classes,)))\n",
    "\n",
    "lrp_model = LSTM_network(n_hidden, embedding_dim, n_classes, weights=weights)\n",
    "\n",
    "def wordsToNum(words):\n",
    "    \"\"\"\n",
    "    :param words:\n",
    "    :return: 40 * 60\n",
    "    \"\"\"\n",
    "    a = list()\n",
    "    for i in words:\n",
    "        a.append(w2v[i])\n",
    "    #\n",
    "    # if len(a) > n_words_len:\n",
    "    #     return a[:n_words_len]\n",
    "    if len(a) < n_words_len:\n",
    "        while len(a) != n_words_len:\n",
    "            a.append([0] * embedding_dim)\n",
    "    return a\n",
    "\n",
    "def readOneLine(line):\n",
    "    a = list(list())\n",
    "    if type(line) is not list:\n",
    "        line = line.split()\n",
    "    a.append(wordsToNum(line))\n",
    "    return np.array(a)\n",
    "\n",
    "def get_result(tokens, vecs):\n",
    "    y_keras = keras_model.predict(vecs)\n",
    "    if n_classes == 1:\n",
    "        # output is 0 - 1\n",
    "        print(\"the class of this sentence is %d\" % (1 if y_keras[0][0] > 0.5 else 0))\n",
    "    elif n_classes == 2:\n",
    "        print(\"the class of this sentence is %d\" % (0 if y_keras[0][0] > y_keras[0][1] else 1))\n",
    "\n",
    "    # explain the classification\n",
    "    eps = 1e-3\n",
    "    bias_factor = 0.0\n",
    "    # by setting y=None, the relevances will be calculated for the predicted class of the sample. We recommend this\n",
    "    # usage, however, if you are interested in the relevances towards the 1st class, you could use y = np.array([1])\n",
    "    explanation, Rest = lrp_model.lrp(vecs, eps=eps, bias_factor=bias_factor)\n",
    "    print(explanation.shape)\n",
    "\n",
    "    # LRP assigns each dimension in the embedding vector a relevance value. To get relevances for each word we can\n",
    "    # sum up these values\n",
    "    word_relevances = tf.reduce_sum(explanation, axis=2)\n",
    "    for word, relevance in zip(tokens, word_relevances[0]):\n",
    "        print('{0:>13}:   {1:8.2f}'.format(word, relevance))\n",
    "\n",
    "    # Whether to draw a picture, default is False\n",
    "    if True:\n",
    "        display(HTML(html_heatmap(tokens, word_relevances[0][:len(tokens)])))\n",
    "    # to check the correctness of the lrp pass we check if all relevance was preserved by using a bias factor of 1.0\n",
    "    print(\n",
    "        \"to check the correctness of the lrp pass we check if all relevance was preserved by using a bias factor of 1.0\")\n",
    "    eps = 0.0\n",
    "    bias_factor = 1.0\n",
    "    explanation, Rest = lrp_model.lrp(vecs, eps=eps, bias_factor=bias_factor)\n",
    "    y_lrpnet, _, _ = lrp_model.full_pass(vecs)\n",
    "    y_lrpnet = y_lrpnet.numpy()\n",
    "    check = np.allclose(np.max(y_lrpnet), np.sum(explanation) + np.sum(Rest))\n",
    "    print('LRP pass is {}.'.format('correct' if check else 'wrong'))\n",
    "\n",
    "    # if all your input sequences have the same length you can process them batch-wise efficiently\n",
    "    if False:\n",
    "        batch_size = 100\n",
    "        length = 10\n",
    "        some_random_data = tf.constant(np.random.randn(batch_size, length, embedding_dim))\n",
    "        # explain 100 instances at once\n",
    "        relevances, _ = lrp_model.lrp(some_random_data)\n",
    "        print(relevances.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "the class of this sentence is 1\n",
      "(1, 40, 60)\n",
      "            i:      -0.98\n",
      "       really:      -0.09\n",
      "      enjoyed:      -1.58\n",
      "         this:      -0.13\n",
      "          one:      -1.81\n",
      "            .:       0.63\n",
      "          the:      -0.49\n",
      "      premise:      -0.01\n",
      "       behind:       0.81\n",
      "           it:       1.88\n",
      "          was:      -1.18\n",
      "         well:       0.69\n",
      "      thought:       0.31\n",
      "          out:      -1.00\n",
      "            .:       2.48\n",
      "            i:       1.91\n",
      "         look:      -0.56\n",
      "      forward:      -1.75\n",
      "           to:       2.29\n",
      "          her:      -0.22\n",
      "    finishing:       0.02\n",
      "         this:       1.00\n",
      "       series:      -0.90\n",
      "            .:       2.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#9a9aff\">i</span> <span style=\"background-color:#f6f6ff\">really</span> <span style=\"background-color:#5c5cff\">enjoyed</span> <span style=\"background-color:#f2f2ff\">this</span> <span style=\"background-color:#4444ff\">one</span> <span style=\"background-color:#ffbebe\">.</span> <span style=\"background-color:#ccccff\">the</span> <span style=\"background-color:#fefeff\">premise</span> <span style=\"background-color:#ffacac\">behind</span> <span style=\"background-color:#ff3e3e\">it</span> <span style=\"background-color:#8686ff\">was</span> <span style=\"background-color:#ffb8b8\">well</span> <span style=\"background-color:#ffe0e0\">thought</span> <span style=\"background-color:#9898ff\">out</span> <span style=\"background-color:#ff0000\">.</span> <span style=\"background-color:#ff3939\">i</span> <span style=\"background-color:#c6c6ff\">look</span> <span style=\"background-color:#4c4cff\">forward</span> <span style=\"background-color:#ff1111\">to</span> <span style=\"background-color:#e8e8ff\">her</span> <span style=\"background-color:#fffcfc\">finishing</span> <span style=\"background-color:#ff9898\">this</span> <span style=\"background-color:#a2a2ff\">series</span> <span style=\"background-color:#ff3030\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to check the correctness of the lrp pass we check if all relevance was preserved by using a bias factor of 1.0\n",
      "LRP pass is correct.\n",
      "2\n",
      "the class of this sentence is 1\n",
      "(1, 40, 60)\n",
      "            i:      -0.51\n",
      "        found:      -0.56\n",
      "         this:      -0.72\n",
      "           to:      -0.49\n",
      "           be:      -0.27\n",
      "            a:      -0.53\n",
      "         very:      -1.02\n",
      "         good:      -0.75\n",
      "         book:      -0.74\n",
      "            .:      -0.54\n",
      "        there:       0.86\n",
      "          was:      -1.11\n",
      "   excitement:       0.57\n",
      "          and:       0.01\n",
      "      romance:       1.31\n",
      "          and:       0.42\n",
      "         even:       1.35\n",
      "       family:       1.83\n",
      "       living:       2.17\n",
      "            a:       2.32\n",
      "       fairly:       0.63\n",
      "    christian:       2.28\n",
      "         life:       3.14\n",
      "            .:       3.64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#dcdcff\">i</span> <span style=\"background-color:#d8d8ff\">found</span> <span style=\"background-color:#ccccff\">this</span> <span style=\"background-color:#dcdcff\">to</span> <span style=\"background-color:#ececff\">be</span> <span style=\"background-color:#dadaff\">a</span> <span style=\"background-color:#b8b8ff\">very</span> <span style=\"background-color:#cacaff\">good</span> <span style=\"background-color:#cacaff\">book</span> <span style=\"background-color:#d8d8ff\">.</span> <span style=\"background-color:#ffc2c2\">there</span> <span style=\"background-color:#b0b0ff\">was</span> <span style=\"background-color:#ffd6d6\">excitement</span> <span style=\"background-color:#fffefe\">and</span> <span style=\"background-color:#ffa3a3\">romance</span> <span style=\"background-color:#ffe2e2\">and</span> <span style=\"background-color:#ffa0a0\">even</span> <span style=\"background-color:#ff7e7e\">family</span> <span style=\"background-color:#ff6666\">living</span> <span style=\"background-color:#ff5c5c\">a</span> <span style=\"background-color:#ffd2d2\">fairly</span> <span style=\"background-color:#ff5e5e\">christian</span> <span style=\"background-color:#ff2121\">life</span> <span style=\"background-color:#ff0000\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to check the correctness of the lrp pass we check if all relevance was preserved by using a bias factor of 1.0\n",
      "LRP pass is correct.\n",
      "3\n",
      "the class of this sentence is 1\n",
      "(1, 40, 60)\n",
      "            i:      -0.18\n",
      "       really:      -0.60\n",
      "        loved:      -0.37\n",
      "         this:      -0.30\n",
      "         book:      -0.47\n",
      "            .:      -0.52\n",
      "           it:       0.10\n",
      "          was:      -1.21\n",
      "            a:       0.38\n",
      "         true:       0.39\n",
      "  page-turner:       0.22\n",
      "            .:       0.88\n",
      "            a:       1.76\n",
      "        great:      -0.27\n",
      "         read:      -0.04\n",
      "          for:       1.18\n",
      "          the:       0.75\n",
      "     hopeless:       0.14\n",
      "     romantic:       0.59\n",
      "      wanting:      -0.60\n",
      "            a:       1.92\n",
      "        happy:       0.09\n",
      "       ending:       0.07\n",
      "            .:       1.10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#e6e6ff\">i</span> <span style=\"background-color:#aeaeff\">really</span> <span style=\"background-color:#ceceff\">loved</span> <span style=\"background-color:#d8d8ff\">this</span> <span style=\"background-color:#c0c0ff\">book</span> <span style=\"background-color:#babaff\">.</span> <span style=\"background-color:#fff2f2\">it</span> <span style=\"background-color:#5e5eff\">was</span> <span style=\"background-color:#ffcccc\">a</span> <span style=\"background-color:#ffcccc\">true</span> <span style=\"background-color:#ffe2e2\">page-turner</span> <span style=\"background-color:#ff8888\">.</span> <span style=\"background-color:#ff1414\">a</span> <span style=\"background-color:#dadaff\">great</span> <span style=\"background-color:#fafaff\">read</span> <span style=\"background-color:#ff6161\">for</span> <span style=\"background-color:#ff9a9a\">the</span> <span style=\"background-color:#ffecec\">hopeless</span> <span style=\"background-color:#ffb0b0\">romantic</span> <span style=\"background-color:#aeaeff\">wanting</span> <span style=\"background-color:#ff0000\">a</span> <span style=\"background-color:#fff4f4\">happy</span> <span style=\"background-color:#fff6f6\">ending</span> <span style=\"background-color:#ff6c6c\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to check the correctness of the lrp pass we check if all relevance was preserved by using a bias factor of 1.0\n",
      "LRP pass is correct.\n",
      "4\n",
      "the class of this sentence is 1\n",
      "(1, 40, 60)\n",
      "           my:       0.88\n",
      "      husband:       0.45\n",
      "            ,:       1.29\n",
      "          who:       0.23\n",
      " particularly:      -0.27\n",
      "       enjoys:      -2.23\n",
      "          dog:       0.80\n",
      "      stories:       0.15\n",
      "          and:       0.89\n",
      "        could:      -0.42\n",
      "          n't:       0.59\n",
      "          put:      -1.78\n",
      "          the:      -0.11\n",
      "         book:       0.16\n",
      "         down:      -0.68\n",
      "        until:      -1.02\n",
      "           it:       1.86\n",
      "          was:      -0.26\n",
      "     finished:      -0.14\n",
      "            ,:       2.00\n",
      "          has:      -0.69\n",
      "        rated:       1.08\n",
      "         this:       1.61\n",
      "        story:       0.40\n",
      "        three:       1.38\n",
      "        stars:       2.20\n",
      "            .:       2.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ff9a9a\">my</span> <span style=\"background-color:#ffcccc\">husband</span> <span style=\"background-color:#ff6c6c\">,</span> <span style=\"background-color:#ffe4e4\">who</span> <span style=\"background-color:#e0e0ff\">particularly</span> <span style=\"background-color:#0000ff\">enjoys</span> <span style=\"background-color:#ffa3a3\">dog</span> <span style=\"background-color:#ffeeee\">stories</span> <span style=\"background-color:#ff9898\">and</span> <span style=\"background-color:#d0d0ff\">could</span> <span style=\"background-color:#ffbcbc\">n't</span> <span style=\"background-color:#3434ff\">put</span> <span style=\"background-color:#f2f2ff\">the</span> <span style=\"background-color:#ffeeee\">book</span> <span style=\"background-color:#b2b2ff\">down</span> <span style=\"background-color:#8a8aff\">until</span> <span style=\"background-color:#ff2929\">it</span> <span style=\"background-color:#e0e0ff\">was</span> <span style=\"background-color:#f0f0ff\">finished</span> <span style=\"background-color:#ff1919\">,</span> <span style=\"background-color:#b0b0ff\">has</span> <span style=\"background-color:#ff8383\">rated</span> <span style=\"background-color:#ff4646\">this</span> <span style=\"background-color:#ffd2d2\">story</span> <span style=\"background-color:#ff6060\">three</span> <span style=\"background-color:#ff0404\">stars</span> <span style=\"background-color:#ff1414\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to check the correctness of the lrp pass we check if all relevance was preserved by using a bias factor of 1.0\n",
      "LRP pass is correct.\n",
      "5\n",
      "the class of this sentence is 1\n",
      "(1, 40, 60)\n",
      "         this:      -0.37\n",
      "       writer:      -0.39\n",
      "           is:      -0.55\n",
      "        quite:      -0.54\n",
      "   insightful:      -0.23\n",
      "          and:       0.74\n",
      "            i:      -0.36\n",
      "         know:       0.25\n",
      "         alot:      -0.10\n",
      "           of:      -0.16\n",
      "      parents:       0.85\n",
      "          who:       0.84\n",
      "         read:      -0.98\n",
      "          and:       0.69\n",
      "       really:       0.30\n",
      "          got:       0.97\n",
      "         what:      -1.05\n",
      "         this:       1.42\n",
      "       writer:       0.33\n",
      "          was:      -0.02\n",
      "       trying:       0.79\n",
      "           to:       1.64\n",
      "          get:       1.63\n",
      "       across:       0.26\n",
      "           to:       2.38\n",
      "          her:       0.80\n",
      "      readers:      -0.29\n",
      "            .:       3.27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#e2e2ff\">this</span> <span style=\"background-color:#e0e0ff\">writer</span> <span style=\"background-color:#d3d3ff\">is</span> <span style=\"background-color:#d3d3ff\">quite</span> <span style=\"background-color:#ececff\">insightful</span> <span style=\"background-color:#ffc3c3\">and</span> <span style=\"background-color:#e2e2ff\">i</span> <span style=\"background-color:#ffecec\">know</span> <span style=\"background-color:#f8f8ff\">alot</span> <span style=\"background-color:#f2f2ff\">of</span> <span style=\"background-color:#ffbcbc\">parents</span> <span style=\"background-color:#ffbcbc\">who</span> <span style=\"background-color:#b2b2ff\">read</span> <span style=\"background-color:#ffcaca\">and</span> <span style=\"background-color:#ffe8e8\">really</span> <span style=\"background-color:#ffb3b3\">got</span> <span style=\"background-color:#acacff\">what</span> <span style=\"background-color:#ff9090\">this</span> <span style=\"background-color:#ffe6e6\">writer</span> <span style=\"background-color:#fefeff\">was</span> <span style=\"background-color:#ffc2c2\">trying</span> <span style=\"background-color:#ff7e7e\">to</span> <span style=\"background-color:#ff8080\">get</span> <span style=\"background-color:#ffeaea\">across</span> <span style=\"background-color:#ff4444\">to</span> <span style=\"background-color:#ffc0c0\">her</span> <span style=\"background-color:#e8e8ff\">readers</span> <span style=\"background-color:#ff0000\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to check the correctness of the lrp pass we check if all relevance was preserved by using a bias factor of 1.0\n",
      "LRP pass is correct.\n",
      "6\n",
      "the class of this sentence is 1\n",
      "(1, 40, 60)\n",
      "            i:      -0.92\n",
      "         will:      -1.22\n",
      "          not:       0.59\n",
      "     hesitate:       0.21\n",
      "           to:       0.09\n",
      "         pick:       0.32\n",
      "           up:      -0.78\n",
      "     anything:       1.31\n",
      "      written:      -3.59\n",
      "           by:      -0.97\n",
      "           ms:       0.13\n",
      "        flynn:       0.26\n",
      "            .:       0.29\n",
      "          boy:       1.72\n",
      "            ,:       1.98\n",
      "          can:      -0.05\n",
      "          she:       2.78\n",
      "        write:       0.10\n",
      "            !:      -0.99\n",
      "          and:       1.95\n",
      "         what:      -1.09\n",
      "       twists:       2.46\n",
      "            &:       2.55\n",
      "        turns:       3.13\n",
      "            !:      -0.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#bebeff\">i</span> <span style=\"background-color:#a8a8ff\">will</span> <span style=\"background-color:#ffd3d3\">not</span> <span style=\"background-color:#fff0f0\">hesitate</span> <span style=\"background-color:#fff8f8\">to</span> <span style=\"background-color:#ffe8e8\">pick</span> <span style=\"background-color:#c8c8ff\">up</span> <span style=\"background-color:#ffa2a2\">anything</span> <span style=\"background-color:#0000ff\">written</span> <span style=\"background-color:#babaff\">by</span> <span style=\"background-color:#fff6f6\">ms</span> <span style=\"background-color:#ffecec\">flynn</span> <span style=\"background-color:#ffeaea\">.</span> <span style=\"background-color:#ff8383\">boy</span> <span style=\"background-color:#ff7171\">,</span> <span style=\"background-color:#fcfcff\">can</span> <span style=\"background-color:#ff3939\">she</span> <span style=\"background-color:#fff8f8\">write</span> <span style=\"background-color:#b8b8ff\">!</span> <span style=\"background-color:#ff7474\">and</span> <span style=\"background-color:#b2b2ff\">what</span> <span style=\"background-color:#ff5050\">twists</span> <span style=\"background-color:#ff4949\">&</span> <span style=\"background-color:#ff2020\">turns</span> <span style=\"background-color:#cacaff\">!</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to check the correctness of the lrp pass we check if all relevance was preserved by using a bias factor of 1.0\n",
      "LRP pass is correct.\n"
     ]
    }
   ],
   "source": [
    "fread = open(\"train_dt/test1.txt\", mode=\"r\", encoding=\"utf-8\")\n",
    "\n",
    "fcont = fread.readlines()\n",
    "i = 0\n",
    "for line in fcont:\n",
    "    line = line.strip()\n",
    "    if line != \"\":\n",
    "        i += 1\n",
    "        print(i)\n",
    "        tokens = line.split()\n",
    "        if len(tokens) > n_words_len:\n",
    "            # The input length is longer than n_words_length, so split it to get the result\n",
    "            n = len(tokens) // n_words_len + 1\n",
    "            for i in range(n):\n",
    "                onceTokens = tokens[i*n_words_len:(i+1)*n_words_len]\n",
    "                vecs = readOneLine(onceTokens)\n",
    "                get_result(onceTokens, vecs)\n",
    "        else:\n",
    "            vecs = readOneLine(line)\n",
    "            get_result(tokens, vecs)\n",
    "\n",
    "        if i > 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
